{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import load_data\n",
    "import argparse\n",
    "import rnn_models\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchtext import data\n",
    "from collections import defaultdict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--max_vocab_size'], dest='max_vocab_size', nargs=None, const=None, default=100000, type=<class 'int'>, choices=None, help='at most n tokens in vocabulary', metavar=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='Testing')\n",
    "parser.add_argument(\"--max_sentence_length\", help=\"maximum sentence length\", type=int, default=50)\n",
    "parser.add_argument(\"--min_freq\", help=\"filter out tokens less than min frequency\", type=int, default=3)\n",
    "parser.add_argument(\"--max_vocab_size\", help=\"at most n tokens in vocabulary\", type=int, default=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args():\n",
    "    \n",
    "    max_sentence_length = 50\n",
    "    min_freq = 3\n",
    "    max_vocab_size = 100000\n",
    "    data = 'data'\n",
    "    hidden_size = 256\n",
    "    embedding_size = 256\n",
    "    bidirectional = True\n",
    "    num_encoder_layers = 2\n",
    "    num_decoder_layers = 2\n",
    "    attn_model = 'default'\n",
    "    lr = 1e-3\n",
    "    epochs = 5\n",
    "    batch_size = 32\n",
    "    \n",
    "args = Args()\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most common source vocabs: [(',', 128638), ('.', 120849), ('là', 51451), ('và', 47993), ('một', 40378), ('tôi', 38381), ('những', 37809), ('của', 36330), ('có', 26166), ('bạn', 26111)]\n",
      "source vocab size: 20125\n",
      "most common english vocabs: [(',', 156165), ('.', 132505), ('the', 109723), ('and', 79673), ('to', 65979), ('of', 60510), ('a', 55374), ('that', 49320), ('i', 43629), ('in', 41318)]\n",
      "english vocab size: 22443\n"
     ]
    }
   ],
   "source": [
    "train_data, val_data, test_data, src, trg = load_data.load_data(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_padding_idx = src.vocab.stoi['<pad>']\n",
    "trg_padding_idx = trg.vocab.stoi['<pad>']\n",
    "\n",
    "src_vocab_size = len(src.vocab)\n",
    "trg_vocab_size = len(trg.vocab)\n",
    "\n",
    "encoder = rnn_models.Encoder(args, src_padding_idx, src_vocab_size)\n",
    "decoder = rnn_models.LuongAttnDecoderRNN(args, trg_padding_idx, trg_vocab_size)\n",
    "\n",
    "# initialize weights using gaussian with 0 mean and 0.01 std, just like the paper said\n",
    "# TODO: Better initialization. Xavier?\n",
    "for net in [encoder, decoder]:\n",
    "    for name, param in net.named_parameters(): \n",
    "        #print(name, type(param), param)\n",
    "        if 'bias' in name:\n",
    "            nn.init.constant_(param, 0.0)\n",
    "        elif 'weight' in name:\n",
    "            nn.init.xavier_normal_(param)\n",
    "            \n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=args.lr)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=args.lr)\n",
    "\n",
    "loss_func = nn.NLLLoss()\n",
    "\n",
    "loss_history = defaultdict(list)\n",
    "bleu_history = defaultdict(list)\n",
    "\n",
    "# for i in range(args.epochs):\n",
    "#     train_loss, val_loss, val_bleu = train_and_val(args, encoder, decoder, encoder_optimizer, \n",
    "#                                                    decoder_optimizer, loss_function, device, i, \n",
    "#                                                    train_data, val_data, trg, encoder_embedding_dict, \n",
    "#                                                    decoder_embedding_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_batch(phase, args, encoder, decoder, encoder_optimizer, decoder_optimizer, loss_func, batch, device):\n",
    "    if phase == \"train\":\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "    \n",
    "    loss = 0\n",
    "    \n",
    "    # TODO: it seems that currently batch size is always the same. Make sure to use the last batch\n",
    "    max_trg_seq_len, batch_size = batch.trg[0].shape\n",
    "    \n",
    "    hidden = encoder.random_init_hidden(device, batch_size)\n",
    "    encoder_outputs, hidden = encoder(hidden, batch.src[0], batch.src[1])\n",
    "    \n",
    "    return 5\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape torch.Size([50, 32])\n",
      "lengths tensor([12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
      "        12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12])\n",
      "embedded:  torch.Size([50, 32, 256])\n",
      "after encoder, encoder_outputs:  torch.Size([12, 32, 512])\n",
      "encoder hidden:  torch.Size([4, 32, 256])\n"
     ]
    }
   ],
   "source": [
    "train_iter = data.BucketIterator(\n",
    "        dataset=train_data, \n",
    "        batch_size=args.batch_size,\n",
    "        repeat=False,\n",
    "        sort_key=lambda x: len(x.src),\n",
    "        sort_within_batch=True,\n",
    "        device=device,\n",
    "        train=True\n",
    "    )\n",
    "    \n",
    "val_iter = data.BucketIterator(\n",
    "    dataset=val_data, \n",
    "    batch_size=args.batch_size,\n",
    "    train=False,\n",
    "    shuffle=False,\n",
    "    #A key to use for sorting examples in order to batch together \n",
    "    # examples with similar lengths and minimize padding.\n",
    "    sort=True,\n",
    "    sort_key=lambda x: len(x.src),\n",
    "    repeat=False,\n",
    "    sort_within_batch=True,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "encoder.train()\n",
    "decoder.train()\n",
    "\n",
    "train_losses = []\n",
    "for i in range(np.random.randint(20)):\n",
    "    batch = next(iter(train_iter))\n",
    "#for i, batch in enumerate(iter(train_iter)):\n",
    "\n",
    "loss = run_batch('train', args, encoder, decoder, encoder_optimizer, decoder_optimizer, loss_func, batch, device)\n",
    "    \n",
    "\n",
    "# `batch` represents a batch. \n",
    "# `batch.src` consists of two tensors. \n",
    "# The first, `b.src[0]`, is the contents of your batch; it's a tensor with the shape (max_seq_len, batch_size). \n",
    "# Your sequences have already been indexed and padded. \n",
    "# The second, `b.src[1]`, is the actual lengths of each sequence. It is of shape (batch_size, 1). \n",
    "\n",
    "# data.BucketIterator automatically batches sequences of similar lengths together. \n",
    "# it also automatically sorts in reverse order. \n",
    "\n",
    "# Say you have a bidirectional, 2-layer RNN encoder. A single batch has max length 19 and batch size 32. \n",
    "# The encoder_outputs will have shape: (19, 32, 512). \n",
    "# Basically, it only returns the topmost layer's hidden states at each step of the sequence. \n",
    "# And it concatenates both directional outputs (hidden states) for the topmost layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = next(iter(train_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 32])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.trg[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_and_val(args, encoder, decoder, encoder_optimizer, decoder_optimizer, loss_function, device, i, \n",
    "#                   train_data, val_data, trg, encoder_embedding_dict, decoder_embedding_dict):\n",
    "    \n",
    "    \n",
    "        \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
