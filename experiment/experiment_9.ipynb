{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 9: Actually use the scheduler (by doing scheduler.step() at the end of every epoch). \n",
    "# I use bleu score, instead of val loss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import loader\n",
    "import argparse\n",
    "import rnn_models\n",
    "# from beam_search import *\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torchtext import data\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pdb\n",
    "import sacrebleu\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import apex\n",
    "from apex import amp\n",
    "from apex.fp16_utils import FP16_Optimizer\n",
    "\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "\n",
    "import io\n",
    "import os\n",
    "import string\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--max_vocab_size'], dest='max_vocab_size', nargs=None, const=None, default=100000, type=<class 'int'>, choices=None, help='at most n tokens in vocabulary', metavar=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='Testing')\n",
    "parser.add_argument(\"--max_sentence_length\", help=\"maximum sentence length\", type=int, default=50)\n",
    "parser.add_argument(\"--min_freq\", help=\"filter out tokens less than min frequency\", type=int, default=3)\n",
    "parser.add_argument(\"--max_vocab_size\", help=\"at most n tokens in vocabulary\", type=int, default=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_NO = 9 \n",
    "OUTPUT_FILE = 'output_{}.txt'.format(EXPERIMENT_NO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "class Args():\n",
    "    \n",
    "    #########\n",
    "    # Paths #\n",
    "    #########\n",
    "    \n",
    "    data = '/scratch/vr1059/vi-en/'\n",
    "    train_prefix = 'train'\n",
    "    val_prefix = 'dev'\n",
    "    test_prefix = 'test'\n",
    "    src_ext = '.tok.vi'\n",
    "    trg_ext = '.tok.en'\n",
    "\n",
    "    max_sentence_length = 50\n",
    "    min_freq = 1\n",
    "    max_vocab_size = 100000\n",
    "    \n",
    "    ################\n",
    "    # Model params #\n",
    "    ################\n",
    "    \n",
    "    hidden_size = 500\n",
    "    embedding_size = 500\n",
    "    bidirectional = True\n",
    "    num_encoder_layers = 2\n",
    "    num_decoder_layers = 2\n",
    "    attn_model = 'general'\n",
    "    lr = 5e-4\n",
    "    epochs = 12\n",
    "    batch_size = 64\n",
    "    print_every = 1000\n",
    "    clip = 0.1\n",
    "    \n",
    "args = Args()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasattr(args, 'hidden_size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most common source vocabs: [(',', 128638), ('.', 120849), ('là', 51451), ('và', 47993), ('một', 40378), ('tôi', 38381), ('những', 37809), ('của', 36330), ('có', 26166), ('bạn', 26111)]\n",
      "source vocab size: 42152\n",
      "most common english vocabs: [(',', 156165), ('.', 132505), ('the', 109723), ('and', 79673), ('to', 65979), ('of', 60510), ('a', 55374), ('that', 49320), ('i', 43629), ('in', 41318)]\n",
      "english vocab size: 47859\n"
     ]
    }
   ],
   "source": [
    "train_data, val_data, test_data, src, trg = loader.load_data(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133166\n",
      "1268\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data))\n",
    "print(len(val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(phase, args, encoder, decoder, encoder_optimizer, decoder_optimizer, loss_func, batch, device):\n",
    "    \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    ###########\n",
    "    # Encoder #\n",
    "    ###########\n",
    "    \n",
    "    seq_len, batch_size = batch.trg[0].shape\n",
    "    hidden = encoder.random_init_hidden(device, batch_size)\n",
    "    encoder_outputs, hidden, encoder_padding_mask = encoder(hidden, batch.src[0], batch.src[1])\n",
    "        \n",
    "    ###########\n",
    "    # Decoder #\n",
    "    ###########\n",
    "    \n",
    "    # Teacher-forcing always ON\n",
    "    \n",
    "    # [2, 2, 2, ..., 2]. List of SOS tokens, batch-sized. \n",
    "    decoder_input = batch.trg[0][0,:] \n",
    "    eos_encountered_list = [False]*batch_size\n",
    "    \n",
    "    i = 0\n",
    "    loss = 0\n",
    "    number_of_loss_calculation = 0\n",
    "    \n",
    "    # decoder.hidden = encoder.hidden[:decoder.n_layers] \n",
    "    # Use last (forward) hidden state from encoder #TODO: verify\n",
    "    hidden = hidden[:decoder.n_layers]\n",
    "    \n",
    "    while ((i+1 < seq_len) and (sum(eos_encountered_list) < batch_size)):\n",
    "        \n",
    "        logits, _, hidden = decoder(hidden, decoder_input, encoder_outputs, encoder_padding_mask)\n",
    "        logits = logits.unsqueeze(0)\n",
    "        class_probs = F.log_softmax(logits, dim = 2)\n",
    "        decoder_input = batch.trg[0][i+1,:]\n",
    "        \n",
    "        # i+1 represents the current index in all sequences\n",
    "        for j in range(batch_size):\n",
    "            if not eos_encountered_list[j]:\n",
    "                loss += loss_func(class_probs[0, j, :].view(1, -1), batch.trg[0][i+1, j].view(1))\n",
    "                number_of_loss_calculation += 1\n",
    "                \n",
    "                if batch.trg[0][i+1, j] == EOS_IDX:\n",
    "                    eos_encountered_list[j] = True\n",
    "                    \n",
    "        i += 1\n",
    "        \n",
    "     \n",
    "    # calculate gradients on each parameter\n",
    "    loss.backward()\n",
    "    \n",
    "    # clip if too large\n",
    "    nn.utils.clip_grad_norm_(encoder.parameters(), args.clip)\n",
    "    nn.utils.clip_grad_norm_(decoder.parameters(), args.clip)\n",
    "\n",
    "    # take gradient step\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "        \n",
    "    # report avg loss over minibatch\n",
    "    return loss.item()/number_of_loss_calculation\n",
    "\n",
    "\n",
    "#               #\n",
    "# Loss function #\n",
    "#               #\n",
    "\n",
    "# loss += loss_func(output[0, j, :].view(1, -1), batch.trg[0][i+1, j].view(1))\n",
    "                \n",
    "# so the way NLLLoss is set up, the target is simply the index that you want to predict. \n",
    "# and the input can be a softmax over the entire output vocabulary space\n",
    "# and nllloss calculate loss value between that index between predicted and \n",
    "# elementary vector e_target_idx (zeroes everywhere except 1 in target index position)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, encoder, decoder, encoder_optimizer, decoder_optimizer, loss_func, device, epoch_idx, \n",
    "                 train_data, val_data, trg):\n",
    "    \n",
    "    \n",
    "    # Create batches with pre-sorted, similar-length sequences in each\n",
    "    train_iter = data.BucketIterator(\n",
    "        dataset=train_data, \n",
    "        batch_size=args.batch_size,\n",
    "        repeat=False,\n",
    "        sort_key=lambda x: len(x.src),\n",
    "        sort_within_batch=True,\n",
    "        device=device,\n",
    "        train=True\n",
    "    )\n",
    "\n",
    "    # Set training flag\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "\n",
    "    train_losses = []\n",
    "    for i, batch in enumerate(iter(train_iter)):\n",
    "        avg_loss = train_batch('train', args, encoder, decoder, encoder_optimizer, decoder_optimizer, loss_func, batch, device)\n",
    "        train_losses.append(avg_loss)\n",
    "        if args.print_every and i % args.print_every == 0:\n",
    "            print(\"train, epoch: {}, batch number: {}, batch loss: {}\".format(\n",
    "            epoch_idx, i, avg_loss))\n",
    "            with open(OUTPUT_FILE, 'a') as f:\n",
    "                f.write(\"\\ntrain, epoch: {}, batch number: {}, batch loss: {}\".format(\n",
    "                    epoch_idx, i, avg_loss))\n",
    "                f.close()\n",
    "            \n",
    "            \n",
    "    print(\"epoch: {}, average loss for epoch: {}, size of last batch {}\".format(\n",
    "    epoch_idx, np.mean(train_losses), batch.src[0].shape[1]))\n",
    "    with open(OUTPUT_FILE, 'a') as f:\n",
    "        f.write(\"\\nepoch: {}, average loss for epoch: {}, size of last batch {}\".format(\n",
    "            epoch_idx, np.mean(train_losses), batch.src[0].shape[1]))\n",
    "        f.close()\n",
    "        \n",
    "    return np.mean(train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bleu(predictions, labels):\n",
    "    \"\"\"\n",
    "    Only pass a list of strings \n",
    "    \"\"\"\n",
    "    # n_gram = 4\n",
    "    for i in range(len(predictions)): \n",
    "        predictions[i] = predictions[i].replace('SOS ', '').replace(' EOS', '')\n",
    "    for i in range(len(labels)):\n",
    "        labels[i] = labels[i].replace('SOS ', '').replace(' EOS', '')\n",
    "        \n",
    "    bleu = sacrebleu.raw_corpus_bleu(predictions, [labels], .01).score\n",
    "    return bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.00000000000004"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_bleu([' i am rich . '], [' i am rich . '])\n",
    "# calculate_bleu(['SOS burma knows what i love .'], ['remi knows what love is . EOS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search(decoder, decoder_input, encoder_outputs, hidden, max_length, k, trg, mask = None):\n",
    "    \n",
    "    candidates = [(decoder_input, 0, hidden)]\n",
    "    potential_candidates = []\n",
    "    completed_translations = []\n",
    "\n",
    "    # put a cap on sentence length\n",
    "    for m in range(max_length):\n",
    "        for c in candidates:\n",
    "            # unpack the tuple\n",
    "            c_sequence, c_score, c_hidden = c\n",
    "            \n",
    "            # EOS token\n",
    "            if c_sequence[-1] == EOS_IDX:\n",
    "                completed_translations.append((c_sequence, c_score))\n",
    "                k = k - 1\n",
    "            else:\n",
    "                logits, _, hidden = decoder(c_hidden.contiguous()[:decoder.n_layers], c_sequence.contiguous()[-1].unsqueeze(0), encoder_outputs, mask)\n",
    "                next_word_probs = F.log_softmax(logits, dim = 1)\n",
    "                # in the worst-case, one sequence will have the highest k probabilities\n",
    "                # so to save computation, only grab the k highest_probability from each candidate sequence\n",
    "                top_probs, top_idx = torch.topk(next_word_probs, k)\n",
    "                top_probs.squeeze_()\n",
    "                top_idx.squeeze_()\n",
    "                top_probs = [top_probs] if len(top_probs.size()) == 0 else top_probs\n",
    "                top_idx = [top_idx] if len(top_idx.size()) == 0 else top_idx\n",
    "                for i in range(len(top_probs)):\n",
    "                    word = top_idx[i].reshape(1, 1).to(device)\n",
    "                    new_score = c_score + top_probs[i]\n",
    "                    potential_candidates.append((torch.cat((c_sequence, word)).to(device), new_score, hidden))\n",
    "\n",
    "        candidates = sorted(potential_candidates, key= lambda x: x[1], reverse=True)[0:k] \n",
    "        potential_candidates = []\n",
    "\n",
    "    completed = completed_translations + candidates\n",
    "    completed = sorted(completed, key= lambda x: x[1], reverse=True)[0] \n",
    "    return completed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ids_to_words(ids, trg):\n",
    "    words = \"\"\n",
    "    for x in ids:\n",
    "        words += trg.vocab.itos[x.squeeze().item()] + ' '\n",
    "    return words.strip()\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chaitra said the best way to get hyperparameters for your model\n",
    "# was to take like 100, 200, 500 examples from your dataset\n",
    "# and see which hyperparameter combination overfits the best/fastest on that example. \n",
    "# And then use that as your hyperparameter combination to train the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_batch(args, encoder, decoder, batch, trg, device):\n",
    "    \n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    \n",
    "    ############\n",
    "    #  encode  #\n",
    "    ############\n",
    "    \n",
    "    _, batch_size = batch.trg[0].shape\n",
    "    hidden = encoder.random_init_hidden(device, batch_size)\n",
    "    encoder_outputs, hidden, _ = encoder(hidden, batch.src[0], batch.src[1])\n",
    "    \n",
    "    #################\n",
    "    #  beam search  #\n",
    "    #################\n",
    "    \n",
    "    max_length = 30\n",
    "    k = 10 \n",
    "    \n",
    "    translations = []\n",
    "    trg_translations = []\n",
    "    for i in range(batch_size):\n",
    "        decoder_input = torch.tensor([[src.vocab.stoi['SOS']]], device=device)\n",
    "        decoder_hidden = hidden[:, i, :].unsqueeze(1)\n",
    "        encoder_outputs_i = encoder_outputs[:, i, :].unsqueeze(1)\n",
    "        \n",
    "        seq_of_ids = beam_search(decoder, decoder_input, encoder_outputs_i, decoder_hidden, max_length, k, trg)\n",
    "        translations.append(ids_to_words(seq_of_ids, trg))\n",
    "        trg_translations.append(ids_to_words(batch.trg[0][:batch.trg[1][i], i], trg))\n",
    "        \n",
    "    return translations, trg_translations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(args, encoder, decoder, device, epoch_idx, val_data, trg):\n",
    "    \n",
    "    # Create minibatches over validation data\n",
    "    val_iter = data.BucketIterator(\n",
    "        dataset=val_data, \n",
    "        batch_size=args.batch_size,\n",
    "        train=False,\n",
    "        shuffle=False,\n",
    "        # A key to use for sorting examples in order to batch together \n",
    "        # examples with similar lengths and minimize padding.\n",
    "        sort=True,\n",
    "        sort_key=lambda x: len(x.src),\n",
    "        repeat=False,\n",
    "        sort_within_batch=True,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    val_losses = []\n",
    "    val_bleus = []\n",
    "    val_references = []\n",
    "    \n",
    "    all_predicted = []\n",
    "    all_trg = []\n",
    "    times = []\n",
    "    for i, batch in enumerate(iter(val_iter)):\n",
    "        start = time.time()\n",
    "        predicted_trans, trg_trans = val_batch(args, encoder, decoder, batch, trg, device)\n",
    "        times.append(time.time() - start)\n",
    "        all_predicted += predicted_trans\n",
    "        all_trg += trg_trans\n",
    "    print(\"Average val_batch time\", np.mean(times))\n",
    "    print(all_predicted[:10])\n",
    "    print(all_trg[:10])    \n",
    "    bleu = calculate_bleu(all_predicted, all_trg)\n",
    "    print(bleu)\n",
    "    with open(OUTPUT_FILE, 'a') as f:\n",
    "        f.write(\"\\nbleu score: {}\\n\".format(bleu))\n",
    "        if epoch_idx % 3 == 0:\n",
    "            f.write(str(all_predicted[:10]) + '\\n')\n",
    "            f.write(str(all_trg[:10]) + '\\n')\n",
    "        f.close()\n",
    "    return bleu\n",
    "    \n",
    "    \n",
    "#                    #\n",
    "# Batch & Dimensions #\n",
    "#                    #\n",
    "# `batch` represents a batch of examples. \n",
    "# `batch.src` consists of two tensors. \n",
    "# The first, `b.src[0]`, is the `src` examples from your batch; it's a tensor with the shape (max_seq_len, batch_size). \n",
    "# Your sequences have already been indexed and padded. \n",
    "# The second, `b.src[1]`, is the actual lengths of each sequence. It is of shape (batch_size, 1). \n",
    "\n",
    "# data.BucketIterator automatically batches sequences of similar lengths together. \n",
    "# it also automatically sorts in reverse order. \n",
    "\n",
    "# Say you have a bidirectional, 2-layer RNN encoder. A single batch has max length 19 and batch size 32. \n",
    "# The encoder_outputs will have shape: (19, 32, 512). \n",
    "# Basically, it only returns the topmost layer's hidden states at each step of the sequence. \n",
    "# And it concatenates both directional outputs (hidden states) for the topmost layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train, epoch: 0, batch number: 0, batch loss: 1.1633004730325998\n"
     ]
    }
   ],
   "source": [
    "src_padding_idx = src.vocab.stoi['<pad>']\n",
    "trg_padding_idx = trg.vocab.stoi['<pad>']\n",
    "EOS_IDX = trg.vocab.stoi['EOS']\n",
    "\n",
    "encoder = rnn_models.Encoder(args, src_padding_idx, len(src.vocab)).to(device)\n",
    "decoder = rnn_models.LuongAttnDecoderRNN(args, trg_padding_idx, len(trg.vocab)).to(device)\n",
    "\n",
    "# initialize weights using gaussian with 0 mean and 0.01 std, just like the paper said\n",
    "# TODO: Better initialization. Xavier?\n",
    "for net in [encoder, decoder]:\n",
    "    for name, param in net.named_parameters(): \n",
    "        #print(name, type(param), param)\n",
    "        if 'bias' in name:\n",
    "            nn.init.constant_(param, 0.0)\n",
    "        elif 'weight' in name:\n",
    "            nn.init.xavier_normal_(param)\n",
    "            \n",
    "# loading in saved models\n",
    "encoder.load_state_dict(torch.load('vi-en_encoder_exp_9.pth'))\n",
    "decoder.load_state_dict(torch.load('vi-en_decoder_exp_9.pth'))\n",
    "    \n",
    "### Apex Nvidia fp16 stuff\n",
    "# encoder_optimizer = FP16_Optimizer(optim.Adam(encoder.parameters(), lr=args.lr))\n",
    "# decoder_optimizer = FP16_Optimizer(optim.Adam(decoder.parameters(), lr=args.lr))\n",
    "\n",
    "# enc_scheduler = ReduceLROnPlateau(encoder_optimizer.optimizer, min_lr=1e-10,factor = 0.5,  patience=0)\n",
    "# dec_scheduler = ReduceLROnPlateau(decoder_optimizer.optimizer, min_lr=1e-10,factor = 0.5,  patience=0)\n",
    "\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=args.lr)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=args.lr)\n",
    "\n",
    "enc_scheduler = ReduceLROnPlateau(encoder_optimizer, min_lr=1e-10,factor = 0.5,  patience=0)\n",
    "dec_scheduler = ReduceLROnPlateau(decoder_optimizer, min_lr=1e-10,factor = 0.5,  patience=0)\n",
    "\n",
    "### Apex Nvidia fp16 stuff\n",
    "# [encoder, decoder], [encoder_optimizer, decoder_optimizer] = amp.initialize(\n",
    "#     [encoder, decoder], \n",
    "#     [encoder_optimizer, decoder_optimizer]\n",
    "# )\n",
    "\n",
    "loss_func = nn.NLLLoss()\n",
    "\n",
    "loss_history = []\n",
    "bleu_history = []\n",
    "\n",
    "for i in range(args.epochs):\n",
    "    avg_epoch_loss = train(args, encoder, decoder, encoder_optimizer, \n",
    "                                     decoder_optimizer, loss_func, device, i, \n",
    "                                    train_data, val_data, trg)\n",
    "    \n",
    "    loss_history.append(avg_epoch_loss)\n",
    "    bleu = val(args, encoder, decoder, device, i, val_data, trg)\n",
    "    bleu_history.append(bleu)\n",
    "    \n",
    "    # Because this originally works with val_loss, whenever val_loss plateaus or goes up, it decreases lr. \n",
    "    # We want it to decrease lr when BLEU score decreases or plateaus. \n",
    "    enc_scheduler.step(-bleu)\n",
    "    dec_scheduler.step(-bleu)\n",
    "    \n",
    "    with open(OUTPUT_FILE, 'a') as f:\n",
    "        f.write(\"\\nLearning rate of encoder_optimizer: {}\".format(get_lr(encoder_optimizer)))\n",
    "        f.write(\"\\nLearning rate of decoder_optimizer: {}\".format(get_lr(decoder_optimizer)))\n",
    "        f.close()\n",
    "    print(\"Learning rate of encoder_optimizer: \", get_lr(encoder_optimizer))\n",
    "    print(\"Learning rate of decoder_optimizer: \", get_lr(decoder_optimizer))\n",
    "    \n",
    "    torch.save(encoder.state_dict(), 'vi-en_encoder_exp_{}.pth'.format(EXPERIMENT_NO))\n",
    "    torch.save(decoder.state_dict(), 'vi-en_decoder_exp_{}.pth'.format(EXPERIMENT_NO))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.184379521845803"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_bleu('this is the kitchen.', ['this is a family portrait.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.455747170954951"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_bleu('SOS i was thrilled . EOS', ['SOS and i was distraught . EOS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.171781507224268\n",
      "0.782250396784411\n"
     ]
    }
   ],
   "source": [
    "print(calculate_bleu(\"SOS you 've got a perfect memory . EOS\", ['SOS he has the most <unk> memory . EOS']))\n",
    "print(calculate_bleu(\"you've got a perfect memory.\", ['he has the most <unk> memory.']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boom = [\"i am a foon\", \"boondawg in the moon.\", \"Yippe.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr\n",
    "func()\n",
    "with open('output.txt', 'a') as f:\n",
    "    f.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func():\n",
    "    for i in range(10):\n",
    "        print(i)\n",
    "        time.sleep(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
