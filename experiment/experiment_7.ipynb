{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 6: Add Attention Mask to basic attention model \n",
    "# Experiment 7: Change beam search window from 2 to 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import loader\n",
    "import argparse\n",
    "import rnn_models\n",
    "# from beam_search import *\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torchtext import data\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pdb\n",
    "import sacrebleu\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "\n",
    "import io\n",
    "import os\n",
    "import string\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--max_vocab_size'], dest='max_vocab_size', nargs=None, const=None, default=100000, type=<class 'int'>, choices=None, help='at most n tokens in vocabulary', metavar=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='Testing')\n",
    "parser.add_argument(\"--max_sentence_length\", help=\"maximum sentence length\", type=int, default=50)\n",
    "parser.add_argument(\"--min_freq\", help=\"filter out tokens less than min frequency\", type=int, default=3)\n",
    "parser.add_argument(\"--max_vocab_size\", help=\"at most n tokens in vocabulary\", type=int, default=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_NO = 7\n",
    "OUTPUT_FILE = 'output_{}.txt'.format(EXPERIMENT_NO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args():\n",
    "    \n",
    "    #########\n",
    "    # Paths #\n",
    "    #########\n",
    "    \n",
    "    data = '/scratch/vr1059/vi-en/'\n",
    "    train_prefix = 'train'\n",
    "    val_prefix = 'dev'\n",
    "    test_prefix = 'test'\n",
    "    src_ext = '.tok.vi'\n",
    "    trg_ext = '.tok.en'\n",
    "\n",
    "    max_sentence_length = 50\n",
    "    min_freq = 1\n",
    "    max_vocab_size = 100000\n",
    "    \n",
    "    ################\n",
    "    # Model params #\n",
    "    ################\n",
    "    \n",
    "    hidden_size = 500\n",
    "    embedding_size = 500\n",
    "    bidirectional = True\n",
    "    num_encoder_layers = 2\n",
    "    num_decoder_layers = 2\n",
    "    attn_model = 'general'\n",
    "    lr = 5e-4\n",
    "    epochs = 12\n",
    "    batch_size = 64\n",
    "    print_every = 1000\n",
    "    clip = 0.1\n",
    "    \n",
    "args = Args()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasattr(args, 'hidden_size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most common source vocabs: [(',', 128638), ('.', 120849), ('là', 51451), ('và', 47993), ('một', 40378), ('tôi', 38381), ('những', 37809), ('của', 36330), ('có', 26166), ('bạn', 26111)]\n",
      "source vocab size: 42152\n",
      "most common english vocabs: [(',', 156165), ('.', 132505), ('the', 109723), ('and', 79673), ('to', 65979), ('of', 60510), ('a', 55374), ('that', 49320), ('i', 43629), ('in', 41318)]\n",
      "english vocab size: 47859\n"
     ]
    }
   ],
   "source": [
    "train_data, val_data, test_data, src, trg = loader.load_data(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133166\n",
      "1268\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data))\n",
    "print(len(val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(phase, args, encoder, decoder, encoder_optimizer, decoder_optimizer, loss_func, batch, device):\n",
    "    \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    ###########\n",
    "    # Encoder #\n",
    "    ###########\n",
    "    \n",
    "    seq_len, batch_size = batch.trg[0].shape\n",
    "    hidden = encoder.random_init_hidden(device, batch_size)\n",
    "    encoder_outputs, hidden, encoder_padding_mask = encoder(hidden, batch.src[0], batch.src[1])\n",
    "        \n",
    "    ###########\n",
    "    # Decoder #\n",
    "    ###########\n",
    "    \n",
    "    # Teacher-forcing always ON\n",
    "    \n",
    "    # [2, 2, 2, ..., 2]. List of SOS tokens, batch-sized. \n",
    "    decoder_input = batch.trg[0][0,:] \n",
    "    eos_encountered_list = [False]*batch_size\n",
    "    \n",
    "    i = 0\n",
    "    loss = 0\n",
    "    number_of_loss_calculation = 0\n",
    "    \n",
    "    # decoder.hidden = encoder.hidden[:decoder.n_layers] \n",
    "    # Use last (forward) hidden state from encoder #TODO: verify\n",
    "    hidden = hidden[:decoder.n_layers]\n",
    "    \n",
    "    while ((i+1 < seq_len) and (sum(eos_encountered_list) < batch_size)):\n",
    "        \n",
    "        logits, _, hidden = decoder(hidden, decoder_input, encoder_outputs, encoder_padding_mask)\n",
    "        logits = logits.unsqueeze(0)\n",
    "        class_probs = F.log_softmax(logits, dim = 2)\n",
    "        decoder_input = batch.trg[0][i+1,:]\n",
    "        \n",
    "        # i+1 represents the current index in all sequences\n",
    "        for j in range(batch_size):\n",
    "            if not eos_encountered_list[j]:\n",
    "                loss += loss_func(class_probs[0, j, :].view(1, -1), batch.trg[0][i+1, j].view(1))\n",
    "                number_of_loss_calculation += 1\n",
    "                \n",
    "                if batch.trg[0][i+1, j] == EOS_IDX:\n",
    "                    eos_encountered_list[j] = True\n",
    "                    \n",
    "        i += 1\n",
    "        \n",
    "     \n",
    "    # calculate gradients on each parameter\n",
    "    loss.backward()\n",
    "    \n",
    "    # clip if too large\n",
    "    nn.utils.clip_grad_norm_(encoder.parameters(), args.clip)\n",
    "    nn.utils.clip_grad_norm_(decoder.parameters(), args.clip)\n",
    "\n",
    "    # take gradient step\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "        \n",
    "    # report avg loss over minibatch\n",
    "    return loss.item()/number_of_loss_calculation\n",
    "\n",
    "\n",
    "#               #\n",
    "# Loss function #\n",
    "#               #\n",
    "\n",
    "# loss += loss_func(output[0, j, :].view(1, -1), batch.trg[0][i+1, j].view(1))\n",
    "                \n",
    "# so the way NLLLoss is set up, the target is simply the index that you want to predict. \n",
    "# and the input can be a softmax over the entire output vocabulary space\n",
    "# and nllloss calculate loss value between that index between predicted and \n",
    "# elementary vector e_target_idx (zeroes everywhere except 1 in target index position)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, encoder, decoder, encoder_optimizer, decoder_optimizer, loss_func, device, epoch_idx, \n",
    "                 train_data, val_data, trg):\n",
    "    \n",
    "    \n",
    "    # Create batches with pre-sorted, similar-length sequences in each\n",
    "    train_iter = data.BucketIterator(\n",
    "        dataset=train_data, \n",
    "        batch_size=args.batch_size,\n",
    "        repeat=False,\n",
    "        sort_key=lambda x: len(x.src),\n",
    "        sort_within_batch=True,\n",
    "        device=device,\n",
    "        train=True\n",
    "    )\n",
    "\n",
    "    # Set training flag\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "\n",
    "    train_losses = []\n",
    "    for i, batch in enumerate(iter(train_iter)):\n",
    "        avg_loss = train_batch('train', args, encoder, decoder, encoder_optimizer, decoder_optimizer, loss_func, batch, device)\n",
    "        train_losses.append(avg_loss)\n",
    "        if args.print_every and i % args.print_every == 0:\n",
    "            print(\"train, epoch: {}, batch number: {}, batch loss: {}\".format(\n",
    "            epoch_idx, i, avg_loss))\n",
    "            with open(OUTPUT_FILE, 'a') as f:\n",
    "                f.write(\"train, epoch: {}, batch number: {}, batch loss: {}\".format(\n",
    "                    epoch_idx, i, avg_loss))\n",
    "                f.close()\n",
    "            \n",
    "            \n",
    "    print(\"epoch: {}, average loss for epoch: {}, size of last batch {}\".format(\n",
    "    epoch_idx, np.mean(train_losses), batch.src[0].shape[1]))\n",
    "    with open(OUTPUT_FILE, 'a') as f:\n",
    "        f.write(\"epoch: {}, average loss for epoch: {}, size of last batch {}\".format(\n",
    "            epoch_idx, np.mean(train_losses), batch.src[0].shape[1]))\n",
    "        f.close()\n",
    "        \n",
    "    return np.mean(train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bleu(predictions, labels):\n",
    "    \"\"\"\n",
    "    Only pass a list of strings \n",
    "    \"\"\"\n",
    "    # n_gram = 4\n",
    "\n",
    "    bleu = sacrebleu.raw_corpus_bleu(predictions, [labels], .01).score\n",
    "    return bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.00000000000004"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_bleu(['I am rich. '], ['I am rich.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search(decoder, decoder_input, encoder_outputs, hidden, max_length, k, trg, mask = None):\n",
    "    \n",
    "    candidates = [(decoder_input, 0, hidden)]\n",
    "    potential_candidates = []\n",
    "    completed_translations = []\n",
    "\n",
    "    # put a cap on sentence length\n",
    "    for m in range(max_length):\n",
    "        for c in candidates:\n",
    "            # unpack the tuple\n",
    "            c_sequence, c_score, c_hidden = c\n",
    "            \n",
    "            # EOS token\n",
    "            if c_sequence[-1] == EOS_IDX:\n",
    "                completed_translations.append((c_sequence, c_score))\n",
    "                k = k - 1\n",
    "            else:\n",
    "                logits, _, hidden = decoder(c_hidden.contiguous()[:decoder.n_layers], c_sequence.contiguous()[-1].unsqueeze(0), encoder_outputs, mask)\n",
    "                next_word_probs = F.log_softmax(logits, dim = 1)\n",
    "                # in the worst-case, one sequence will have the highest k probabilities\n",
    "                # so to save computation, only grab the k highest_probability from each candidate sequence\n",
    "                top_probs, top_idx = torch.topk(next_word_probs, k)\n",
    "                top_probs.squeeze_()\n",
    "                top_idx.squeeze_()\n",
    "                top_probs = [top_probs] if len(top_probs.size()) == 0 else top_probs\n",
    "                top_idx = [top_idx] if len(top_idx.size()) == 0 else top_idx\n",
    "                for i in range(len(top_probs)):\n",
    "                    word = top_idx[i].reshape(1, 1).to(device)\n",
    "                    new_score = c_score + top_probs[i]\n",
    "                    potential_candidates.append((torch.cat((c_sequence, word)).to(device), new_score, hidden))\n",
    "\n",
    "        candidates = sorted(potential_candidates, key= lambda x: x[1], reverse=True)[0:k] \n",
    "        potential_candidates = []\n",
    "\n",
    "    completed = completed_translations + candidates\n",
    "    completed = sorted(completed, key= lambda x: x[1], reverse=True)[0] \n",
    "    return completed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ids_to_words(ids, trg):\n",
    "    words = \"\"\n",
    "    for x in ids:\n",
    "        words += trg.vocab.itos[x.squeeze().item()] + ' '\n",
    "    return words.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chaitra said the best way to get hyperparameters for your model\n",
    "# was to take like 100, 200, 500 examples from your dataset\n",
    "# and see which hyperparameter combination overfits the best/fastest on that example. \n",
    "# And then use that as your hyperparameter combination to train the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_batch(args, encoder, decoder, encoder_optimizer, decoder_optimizer, loss_func, batch, trg, device):\n",
    "    \n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    \n",
    "    ############\n",
    "    #  encode  #\n",
    "    ############\n",
    "    \n",
    "    _, batch_size = batch.trg[0].shape\n",
    "    hidden = encoder.random_init_hidden(device, batch_size)\n",
    "    encoder_outputs, hidden, _ = encoder(hidden, batch.src[0], batch.src[1])\n",
    "    \n",
    "    #################\n",
    "    #  beam search  #\n",
    "    #################\n",
    "    \n",
    "    max_length = 30\n",
    "    k = 10 \n",
    "    \n",
    "    translations = []\n",
    "    trg_translations = []\n",
    "    for i in range(batch_size):\n",
    "        decoder_input = torch.tensor([[src.vocab.stoi['SOS']]], device=device)\n",
    "        decoder_hidden = hidden[:, i, :].unsqueeze(1)\n",
    "        encoder_outputs_i = encoder_outputs[:, i, :].unsqueeze(1)\n",
    "\n",
    "        seq_of_ids = beam_search(decoder, decoder_input, encoder_outputs_i, decoder_hidden, max_length, k, trg)\n",
    "        translations.append(ids_to_words(seq_of_ids, trg))\n",
    "        trg_translations.append(ids_to_words(batch.trg[0][:batch.trg[1][i], i], trg))\n",
    "        \n",
    "    return translations, trg_translations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(args, encoder, decoder, encoder_optimizer, decoder_optimizer, loss_func, device, epoch_idx, \n",
    "        val_data, trg):\n",
    "    \n",
    "    # Create minibatches over validation data\n",
    "    val_iter = data.BucketIterator(\n",
    "        dataset=val_data, \n",
    "        batch_size=args.batch_size,\n",
    "        train=False,\n",
    "        shuffle=False,\n",
    "        # A key to use for sorting examples in order to batch together \n",
    "        # examples with similar lengths and minimize padding.\n",
    "        sort=True,\n",
    "        sort_key=lambda x: len(x.src),\n",
    "        repeat=False,\n",
    "        sort_within_batch=True,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    val_losses = []\n",
    "    val_bleus = []\n",
    "    val_references = []\n",
    "    \n",
    "    all_predicted = []\n",
    "    all_trg = []\n",
    "    for i, batch in enumerate(iter(val_iter)):\n",
    "        predicted_trans, trg_trans = val_batch(args, encoder, decoder, encoder_optimizer, decoder_optimizer, loss_func, batch, trg, device)\n",
    "        all_predicted += predicted_trans\n",
    "        all_trg += trg_trans\n",
    "    print(all_predicted[:10])\n",
    "    print(all_trg[:10])    \n",
    "    bleu = calculate_bleu(all_predicted, all_trg)\n",
    "    print(bleu)\n",
    "    if epoch_idx % 3 == 0:\n",
    "        with open(OUTPUT_FILE, 'a') as f:\n",
    "            f.write(str(all_predicted[:10]))\n",
    "            f.write(str(all_trg[:10]))\n",
    "            f.write(\"bleu score: {}\".format(bleu))\n",
    "            f.close()\n",
    "    return bleu\n",
    "    \n",
    "    \n",
    "#                    #\n",
    "# Batch & Dimensions #\n",
    "#                    #\n",
    "# `batch` represents a batch of examples. \n",
    "# `batch.src` consists of two tensors. \n",
    "# The first, `b.src[0]`, is the `src` examples from your batch; it's a tensor with the shape (max_seq_len, batch_size). \n",
    "# Your sequences have already been indexed and padded. \n",
    "# The second, `b.src[1]`, is the actual lengths of each sequence. It is of shape (batch_size, 1). \n",
    "\n",
    "# data.BucketIterator automatically batches sequences of similar lengths together. \n",
    "# it also automatically sorts in reverse order. \n",
    "\n",
    "# Say you have a bidirectional, 2-layer RNN encoder. A single batch has max length 19 and batch size 32. \n",
    "# The encoder_outputs will have shape: (19, 32, 512). \n",
    "# Basically, it only returns the topmost layer's hidden states at each step of the sequence. \n",
    "# And it concatenates both directional outputs (hidden states) for the topmost layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train, epoch: 0, batch number: 0, batch loss: 10.775885723440227\n",
      "train, epoch: 0, batch number: 1000, batch loss: 5.339151278409091\n",
      "train, epoch: 0, batch number: 2000, batch loss: 4.40697045669317\n",
      "epoch: 0, average loss for epoch: 5.466798213057836, size of last batch 64\n",
      "[\"SOS it 's a lot . EOS\", \"SOS let 's do it . EOS\", 'SOS one of the world . EOS', \"SOS and it 's in the world . EOS\", 'SOS so this is the internet . EOS', \"SOS it 's all it . EOS\", 'SOS this is it . EOS', 'SOS we went to the world . EOS', 'SOS what do it ? EOS', \"SOS i didn 't . EOS\"]\n",
      "['SOS he has the most <unk> memory . EOS', 'SOS remi knows what love is . EOS', 'SOS kofi is the embodiment of possibility . EOS', 'SOS in the cold , windy night . EOS', 'SOS this is a family portrait . EOS', 'SOS it was very time-consuming . EOS', 'SOS this was the very first . EOS', 'SOS we activate communities . EOS', 'SOS guess what ? EOS', 'SOS and i was distraught . EOS']\n",
      "4.352048521687093\n",
      "train, epoch: 1, batch number: 0, batch loss: 5.002324661867365\n",
      "train, epoch: 1, batch number: 1000, batch loss: 4.113054230925325\n",
      "train, epoch: 1, batch number: 2000, batch loss: 3.5785157777470022\n",
      "epoch: 1, average loss for epoch: 4.131856572083862, size of last batch 64\n",
      "['SOS i have a company . EOS', \"SOS the answer knows what 's wrong . EOS\", 'SOS art is the future . EOS', 'SOS of course . EOS', 'SOS this is a couple of time . EOS', \"SOS it 's very time . EOS\", 'SOS this is the first time . EOS', 'SOS we use the world . EOS', 'SOS think about ? EOS', 'SOS i was very excited . EOS']\n",
      "['SOS he has the most <unk> memory . EOS', 'SOS remi knows what love is . EOS', 'SOS kofi is the embodiment of possibility . EOS', 'SOS in the cold , windy night . EOS', 'SOS this is a family portrait . EOS', 'SOS it was very time-consuming . EOS', 'SOS this was the very first . EOS', 'SOS we activate communities . EOS', 'SOS guess what ? EOS', 'SOS and i was distraught . EOS']\n",
      "7.782392134341186\n",
      "train, epoch: 2, batch number: 0, batch loss: 4.318772241083115\n",
      "train, epoch: 2, batch number: 1000, batch loss: 3.5332187669101733\n",
      "train, epoch: 2, batch number: 2000, batch loss: 3.0969100808948125\n",
      "epoch: 2, average loss for epoch: 3.559341832428473, size of last batch 64\n",
      "['SOS and i have a very serious idea . EOS', \"SOS voice knows what 's . EOS\", 'SOS art is a robot . EOS', 'SOS in the top of the left . EOS', 'SOS this is a family . EOS', \"SOS it 's very time . EOS\", 'SOS this is the first time . EOS', 'SOS we accumulate the community . EOS', 'SOS think ? EOS', 'SOS i was very excited . EOS']\n",
      "['SOS he has the most <unk> memory . EOS', 'SOS remi knows what love is . EOS', 'SOS kofi is the embodiment of possibility . EOS', 'SOS in the cold , windy night . EOS', 'SOS this is a family portrait . EOS', 'SOS it was very time-consuming . EOS', 'SOS this was the very first . EOS', 'SOS we activate communities . EOS', 'SOS guess what ? EOS', 'SOS and i was distraught . EOS']\n",
      "11.338944604710537\n",
      "train, epoch: 3, batch number: 0, batch loss: 3.8855082726603403\n",
      "train, epoch: 3, batch number: 2000, batch loss: 2.755391460016945\n",
      "epoch: 3, average loss for epoch: 3.1543493263182154, size of last batch 64\n",
      "['SOS i have a perfect mirror . EOS', \"SOS well , let 's know the answer . EOS\", 'SOS hollywood is the same . EOS', 'SOS in the netherlands . EOS', 'SOS this is a hydras . EOS', \"SOS it 's very time . EOS\", 'SOS this is the first one . EOS', 'SOS we accumulate the communities . EOS', 'SOS think ? EOS', 'SOS i was very nervous . EOS']\n",
      "['SOS he has the most <unk> memory . EOS', 'SOS remi knows what love is . EOS', 'SOS kofi is the embodiment of possibility . EOS', 'SOS in the cold , windy night . EOS', 'SOS this is a family portrait . EOS', 'SOS it was very time-consuming . EOS', 'SOS this was the very first . EOS', 'SOS we activate communities . EOS', 'SOS guess what ? EOS', 'SOS and i was distraught . EOS']\n",
      "13.429404973095743\n",
      "train, epoch: 4, batch number: 0, batch loss: 3.560102266374891\n",
      "train, epoch: 4, batch number: 1000, batch loss: 2.809764779491342\n",
      "train, epoch: 4, batch number: 2000, batch loss: 2.5012123020398853\n",
      "epoch: 4, average loss for epoch: 2.8475223409168797, size of last batch 64\n",
      "['SOS you have a perfect memory . EOS', 'SOS ak knows the love of love . EOS', 'SOS misha is a neuroscientific machine . EOS', 'SOS in the end of the end . EOS', 'SOS this is my family . EOS', \"SOS it 's time for time . EOS\", 'SOS this is the first one . EOS', 'SOS we negotiate our communities . EOS', 'SOS think about it ? EOS', 'SOS i had a crossfader . EOS']\n",
      "['SOS he has the most <unk> memory . EOS', 'SOS remi knows what love is . EOS', 'SOS kofi is the embodiment of possibility . EOS', 'SOS in the cold , windy night . EOS', 'SOS this is a family portrait . EOS', 'SOS it was very time-consuming . EOS', 'SOS this was the very first . EOS', 'SOS we activate communities . EOS', 'SOS guess what ? EOS', 'SOS and i was distraught . EOS']\n",
      "15.161473748274897\n",
      "train, epoch: 5, batch number: 0, batch loss: 3.291311320626091\n",
      "train, epoch: 5, batch number: 1000, batch loss: 2.5295424952651517\n",
      "train, epoch: 5, batch number: 2000, batch loss: 2.2316670502313607\n",
      "epoch: 5, average loss for epoch: 2.6048166443626894, size of last batch 64\n",
      "['SOS you have a perfect memory . EOS', 'SOS shaffi . EOS', 'SOS parusharam is a dilemma . EOS', 'SOS in the dark layer . EOS', 'SOS this is tensor . EOS', \"SOS it 's over time . EOS\", 'SOS this is the first one . EOS', 'SOS we divide our communities . EOS', 'SOS think about it ? EOS', 'SOS i was very petrified . EOS']\n",
      "['SOS he has the most <unk> memory . EOS', 'SOS remi knows what love is . EOS', 'SOS kofi is the embodiment of possibility . EOS', 'SOS in the cold , windy night . EOS', 'SOS this is a family portrait . EOS', 'SOS it was very time-consuming . EOS', 'SOS this was the very first . EOS', 'SOS we activate communities . EOS', 'SOS guess what ? EOS', 'SOS and i was distraught . EOS']\n",
      "16.4771116183582\n",
      "train, epoch: 6, batch number: 0, batch loss: 3.1270070234102314\n",
      "train, epoch: 6, batch number: 1000, batch loss: 2.338979640151515\n",
      "train, epoch: 6, batch number: 2000, batch loss: 1.9768779225593065\n",
      "epoch: 6, average loss for epoch: 2.4110008811449175, size of last batch 64\n",
      "['SOS i have a perfect memory . EOS', 'SOS riley knows love . EOS', 'SOS hillel is the paradox of the potential . EOS', 'SOS in the winter of the lake . EOS', 'SOS this is a hydras . EOS', \"SOS it 's so much time . EOS\", 'SOS this is the first one . EOS', 'SOS we put our communities . EOS', 'SOS think about it ? EOS', 'SOS i was very marginalized . EOS']\n",
      "['SOS he has the most <unk> memory . EOS', 'SOS remi knows what love is . EOS', 'SOS kofi is the embodiment of possibility . EOS', 'SOS in the cold , windy night . EOS', 'SOS this is a family portrait . EOS', 'SOS it was very time-consuming . EOS', 'SOS this was the very first . EOS', 'SOS we activate communities . EOS', 'SOS guess what ? EOS', 'SOS and i was distraught . EOS']\n",
      "17.23324899634522\n",
      "train, epoch: 7, batch number: 0, batch loss: 2.9748343422774868\n",
      "train, epoch: 7, batch number: 1000, batch loss: 2.2090496905438313\n",
      "train, epoch: 7, batch number: 2000, batch loss: 1.828951488570451\n",
      "epoch: 7, average loss for epoch: 2.2482590276598136, size of last batch 64\n",
      "['SOS you have a perfect memory . EOS', 'SOS shame knows what love is . EOS', 'SOS hillel is the core revolution . EOS', 'SOS in the end of the cold circle . EOS', 'SOS this is a family . EOS', \"SOS it 's a lot of time . EOS\", 'SOS this is the first one . EOS', 'SOS we turn our communities . EOS', 'SOS think about that ? EOS', 'SOS i was marginalized . EOS']\n",
      "['SOS he has the most <unk> memory . EOS', 'SOS remi knows what love is . EOS', 'SOS kofi is the embodiment of possibility . EOS', 'SOS in the cold , windy night . EOS', 'SOS this is a family portrait . EOS', 'SOS it was very time-consuming . EOS', 'SOS this was the very first . EOS', 'SOS we activate communities . EOS', 'SOS guess what ? EOS', 'SOS and i was distraught . EOS']\n",
      "18.37467496448506\n",
      "train, epoch: 8, batch number: 0, batch loss: 2.804309785053992\n",
      "train, epoch: 8, batch number: 1000, batch loss: 2.0820314613771647\n",
      "train, epoch: 8, batch number: 2000, batch loss: 1.6883045948334854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8, average loss for epoch: 2.1142746029058803, size of last batch 64\n",
      "['SOS you have a perfect memory . EOS', 'SOS burma knows what love is . EOS', 'SOS durkheim is the core of the necessity . EOS', 'SOS in the dark of the cold season . EOS', 'SOS this is a family portrait . EOS', \"SOS it 's very time-consuming . EOS\", \"SOS here 's the first one . EOS\", 'SOS we turn the communities . EOS', 'SOS think what ? EOS', 'SOS i was very marginalized . EOS']\n",
      "['SOS he has the most <unk> memory . EOS', 'SOS remi knows what love is . EOS', 'SOS kofi is the embodiment of possibility . EOS', 'SOS in the cold , windy night . EOS', 'SOS this is a family portrait . EOS', 'SOS it was very time-consuming . EOS', 'SOS this was the very first . EOS', 'SOS we activate communities . EOS', 'SOS guess what ? EOS', 'SOS and i was distraught . EOS']\n",
      "18.259869490282885\n",
      "train, epoch: 9, batch number: 0, batch loss: 2.722850965995855\n",
      "train, epoch: 9, batch number: 1000, batch loss: 2.0386813869724025\n",
      "train, epoch: 9, batch number: 2000, batch loss: 1.6575068532488269\n",
      "epoch: 9, average loss for epoch: 2.002193224929707, size of last batch 64\n"
     ]
    }
   ],
   "source": [
    "src_padding_idx = src.vocab.stoi['<pad>']\n",
    "trg_padding_idx = trg.vocab.stoi['<pad>']\n",
    "EOS_IDX = trg.vocab.stoi['EOS']\n",
    "\n",
    "encoder = rnn_models.Encoder(args, src_padding_idx, len(src.vocab)).to(device)\n",
    "decoder = rnn_models.LuongAttnDecoderRNN(args, trg_padding_idx, len(trg.vocab)).to(device)\n",
    "\n",
    "# initialize weights using gaussian with 0 mean and 0.01 std, just like the paper said\n",
    "# TODO: Better initialization. Xavier?\n",
    "for net in [encoder, decoder]:\n",
    "    for name, param in net.named_parameters(): \n",
    "        #print(name, type(param), param)\n",
    "        if 'bias' in name:\n",
    "            nn.init.constant_(param, 0.0)\n",
    "        elif 'weight' in name:\n",
    "            nn.init.xavier_normal_(param)\n",
    "            \n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=args.lr)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=args.lr)\n",
    "enc_scheduler = ReduceLROnPlateau(encoder_optimizer, min_lr=1e-10,factor = 0.5,  patience=0)\n",
    "dec_scheduler = ReduceLROnPlateau(decoder_optimizer, min_lr=1e-10,factor = 0.5,  patience=0)\n",
    "\n",
    "loss_func = nn.NLLLoss()\n",
    "\n",
    "loss_history = []\n",
    "bleu_history = []\n",
    "\n",
    "for i in range(args.epochs):\n",
    "    train_loss = train(args, encoder, decoder, encoder_optimizer, \n",
    "                                     decoder_optimizer, loss_func, device, i, \n",
    "                                    train_data, val_data, trg)\n",
    "    \n",
    "    loss_history.append(train_loss)\n",
    "    bleu = val(args, encoder, decoder, encoder_optimizer, decoder_optimizer, loss_func, device, i, val_data, trg)\n",
    "    bleu_history.append(bleu)\n",
    "    \n",
    "    torch.save(encoder.state_dict(), 'vi-en_encoder_exp_{}.pth'.format(EXPERIMENT_NO))\n",
    "    torch.save(decoder.state_dict(), 'vi-en_decoder_exp_{}.pth'.format(EXPERIMENT_NO))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.184379521845803"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_bleu('this is the kitchen.', ['this is a family portrait.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.455747170954951"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_bleu('SOS i was thrilled . EOS', ['SOS and i was distraught . EOS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.171781507224268\n",
      "0.782250396784411\n"
     ]
    }
   ],
   "source": [
    "print(calculate_bleu(\"SOS you 've got a perfect memory . EOS\", ['SOS he has the most <unk> memory . EOS']))\n",
    "print(calculate_bleu(\"you've got a perfect memory.\", ['he has the most <unk> memory.']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boom = [\"i am a foon\", \"boondawg in the moon.\", \"Yippe.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr\n",
    "func()\n",
    "with open('output.txt', 'a') as f:\n",
    "    f.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func():\n",
    "    for i in range(10):\n",
    "        print(i)\n",
    "        time.sleep(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
