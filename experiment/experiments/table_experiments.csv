id~question~outcome
1~can i overfit on a small dataset~yes but i have to crank up the epochs to a lot and loss values were very noisy at first which frustrated me but it seems to learn slowly at first and at epoch 49 you can clearly see that it memorizes the train data and train loss is very low (like 1.97)
2~how well can i do using full train set & standard attention (lr scheduler) (no hyperparam search) (no masking) (clip 1)~pretty bad 5e-3 Adam & gradient clip 1 never really learned hm it got from 10.7 to 7 and then oscillated around 6 and 7 for 11 epochs hmm i wonder if my modules are working properly or maybe beam search maybe i should try just greedy search
3~losses in 2 don't look good (seem to be oscillating around same values every epoch) so will decreasing the learning rate and gradient clip to 0.1 work~absolutely great: all i had to do was decrease learning rate from 5e-3 to 5e-4 and suddenly loss values go all the way down until 1.7 & bleu score is 11 & the model is very clearly working wow...along with learning rate and lr scheduler my beam search seems to be working perfectly!
