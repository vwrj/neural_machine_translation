{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import loader\n",
    "import argparse\n",
    "import rnn_models\n",
    "# from beam_search import *\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torchtext import data\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pdb\n",
    "import sacrebleu\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "\n",
    "import io\n",
    "import os\n",
    "import string\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--max_vocab_size'], dest='max_vocab_size', nargs=None, const=None, default=100000, type=<class 'int'>, choices=None, help='at most n tokens in vocabulary', metavar=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='Testing')\n",
    "parser.add_argument(\"--max_sentence_length\", help=\"maximum sentence length\", type=int, default=50)\n",
    "parser.add_argument(\"--min_freq\", help=\"filter out tokens less than min frequency\", type=int, default=3)\n",
    "parser.add_argument(\"--max_vocab_size\", help=\"at most n tokens in vocabulary\", type=int, default=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_FILE = 'output_3.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args():\n",
    "    \n",
    "    #########\n",
    "    # Paths #\n",
    "    #########\n",
    "    \n",
    "    data = '/scratch/vr1059/vi-en/'\n",
    "    train_prefix = 'train'\n",
    "    val_prefix = 'dev'\n",
    "    test_prefix = 'test'\n",
    "    src_ext = '.tok.vi'\n",
    "    trg_ext = '.tok.en'\n",
    "\n",
    "    max_sentence_length = 50\n",
    "    min_freq = 1\n",
    "    max_vocab_size = 100000\n",
    "    \n",
    "    ################\n",
    "    # Model params #\n",
    "    ################\n",
    "    \n",
    "    hidden_size = 500\n",
    "    embedding_size = 500\n",
    "    bidirectional = True\n",
    "    num_encoder_layers = 2\n",
    "    num_decoder_layers = 2\n",
    "    attn_model = 'general'\n",
    "    lr = 5e-4\n",
    "    epochs = 12\n",
    "    batch_size = 64\n",
    "    print_every = 1000\n",
    "    clip = 0.1\n",
    "    \n",
    "args = Args()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most common source vocabs: [(',', 128638), ('.', 120849), ('là', 51451), ('và', 47993), ('một', 40378), ('tôi', 38381), ('những', 37809), ('của', 36330), ('có', 26166), ('bạn', 26111)]\n",
      "source vocab size: 42152\n",
      "most common english vocabs: [(',', 156165), ('.', 132505), ('the', 109723), ('and', 79673), ('to', 65979), ('of', 60510), ('a', 55374), ('that', 49320), ('i', 43629), ('in', 41318)]\n",
      "english vocab size: 47859\n"
     ]
    }
   ],
   "source": [
    "train_data, val_data, test_data, src, trg = loader.load_data(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133166\n",
      "1268\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data))\n",
    "print(len(val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(phase, args, encoder, decoder, encoder_optimizer, decoder_optimizer, loss_func, batch, device):\n",
    "    \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    ###########\n",
    "    # Encoder #\n",
    "    ###########\n",
    "    \n",
    "    seq_len, batch_size = batch.trg[0].shape\n",
    "    hidden = encoder.random_init_hidden(device, batch_size)\n",
    "    encoder_outputs, hidden = encoder(hidden, batch.src[0], batch.src[1])  \n",
    "    \n",
    "    ###########\n",
    "    # Decoder #\n",
    "    ###########\n",
    "    \n",
    "    # Teacher-forcing always ON\n",
    "    \n",
    "    # [2, 2, 2, ..., 2]. List of SOS tokens, batch-sized. \n",
    "    decoder_input = batch.trg[0][0,:] \n",
    "    eos_encountered_list = [False]*batch_size\n",
    "    \n",
    "    i = 0\n",
    "    loss = 0\n",
    "    number_of_loss_calculation = 0\n",
    "    \n",
    "    # decoder.hidden = encoder.hidden[:decoder.n_layers] \n",
    "    # Use last (forward) hidden state from encoder #TODO: verify\n",
    "    hidden = hidden[:decoder.n_layers]\n",
    "    \n",
    "    while ((i+1 < seq_len) and (sum(eos_encountered_list) < batch_size)):\n",
    "        \n",
    "        logits, _, hidden = decoder(hidden, decoder_input, encoder_outputs)\n",
    "        logits = logits.unsqueeze(0)\n",
    "        class_probs = F.log_softmax(logits, dim = 2)\n",
    "        decoder_input = batch.trg[0][i+1,:]\n",
    "        \n",
    "        # i+1 represents the current index in all sequences\n",
    "        for j in range(batch_size):\n",
    "            if not eos_encountered_list[j]:\n",
    "                loss += loss_func(class_probs[0, j, :].view(1, -1), batch.trg[0][i+1, j].view(1))\n",
    "                number_of_loss_calculation += 1\n",
    "                \n",
    "                if batch.trg[0][i+1, j] == EOS_IDX:\n",
    "                    eos_encountered_list[j] = True\n",
    "                    \n",
    "        i += 1\n",
    "        \n",
    "     \n",
    "    # calculate gradients on each parameter\n",
    "    loss.backward()\n",
    "    \n",
    "    # clip if too large\n",
    "    nn.utils.clip_grad_norm_(encoder.parameters(), args.clip)\n",
    "    nn.utils.clip_grad_norm_(decoder.parameters(), args.clip)\n",
    "\n",
    "    # take gradient step\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "        \n",
    "    # report avg loss over minibatch\n",
    "    return loss.item()/number_of_loss_calculation\n",
    "\n",
    "\n",
    "#               #\n",
    "# Loss function #\n",
    "#               #\n",
    "\n",
    "# loss += loss_func(output[0, j, :].view(1, -1), batch.trg[0][i+1, j].view(1))\n",
    "                \n",
    "# so the way NLLLoss is set up, the target is simply the index that you want to predict. \n",
    "# and the input can be a softmax over the entire output vocabulary space\n",
    "# and nllloss calculate loss value between that index between predicted and \n",
    "# elementary vector e_target_idx (zeroes everywhere except 1 in target index position)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, encoder, decoder, encoder_optimizer, decoder_optimizer, loss_func, device, epoch_idx, \n",
    "                 train_data, val_data, trg):\n",
    "    \n",
    "    \n",
    "    # Create batches with pre-sorted, similar-length sequences in each\n",
    "    train_iter = data.BucketIterator(\n",
    "        dataset=train_data, \n",
    "        batch_size=args.batch_size,\n",
    "        repeat=False,\n",
    "        sort_key=lambda x: len(x.src),\n",
    "        sort_within_batch=True,\n",
    "        device=device,\n",
    "        train=True\n",
    "    )\n",
    "\n",
    "    # Set training flag\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "\n",
    "    train_losses = []\n",
    "    for i, batch in enumerate(iter(train_iter)):\n",
    "        avg_loss = train_batch('train', args, encoder, decoder, encoder_optimizer, decoder_optimizer, loss_func, batch, device)\n",
    "        train_losses.append(avg_loss)\n",
    "        if args.print_every and i % args.print_every == 0:\n",
    "            print(\"train, epoch: {}, batch number: {}, batch loss: {}\".format(\n",
    "            epoch_idx, i, avg_loss))\n",
    "            with open(OUTPUT_FILE, 'a') as f:\n",
    "                f.write(\"train, epoch: {}, batch number: {}, batch loss: {}\".format(\n",
    "                    epoch_idx, i, avg_loss))\n",
    "                f.close()\n",
    "            \n",
    "            \n",
    "    print(\"epoch: {}, average loss for epoch: {}, size of last batch {}\".format(\n",
    "    epoch_idx, np.mean(train_losses), batch.src[0].shape[1]))\n",
    "    with open(OUTPUT_FILE, 'a') as f:\n",
    "        f.write(\"epoch: {}, average loss for epoch: {}, size of last batch {}\".format(\n",
    "            epoch_idx, np.mean(train_losses), batch.src[0].shape[1]))\n",
    "        f.close()\n",
    "        \n",
    "    return np.mean(train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bleu(predictions, labels):\n",
    "    \"\"\"\n",
    "    Only pass a list of strings \n",
    "    \"\"\"\n",
    "    # n_gram = 4\n",
    "\n",
    "    bleu = sacrebleu.raw_corpus_bleu(predictions, [labels], .01).score\n",
    "    return bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.00000000000004"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_bleu(['I am rich. '], ['I am rich.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search(decoder, decoder_input, encoder_outputs, hidden, max_length, k, trg):\n",
    "    \n",
    "    candidates = [(decoder_input, 0, hidden)]\n",
    "    potential_candidates = []\n",
    "    completed_translations = []\n",
    "\n",
    "    # put a cap on sentence length\n",
    "    for m in range(max_length):\n",
    "        for c in candidates:\n",
    "            # unpack the tuple\n",
    "            c_sequence, c_score, c_hidden = c\n",
    "            \n",
    "            # EOS token\n",
    "            if c_sequence[-1] == EOS_IDX:\n",
    "                completed_translations.append((c_sequence, c_score))\n",
    "                k = k - 1\n",
    "            else:\n",
    "                logits, _, hidden = decoder(c_hidden.contiguous()[:decoder.n_layers], c_sequence.contiguous()[-1].unsqueeze(0), encoder_outputs)\n",
    "                next_word_probs = F.log_softmax(logits, dim = 1)\n",
    "                # in the worst-case, one sequence will have the highest k probabilities\n",
    "                # so to save computation, only grab the k highest_probability from each candidate sequence\n",
    "                top_probs, top_idx = torch.topk(next_word_probs, k)\n",
    "                top_probs.squeeze_()\n",
    "                top_idx.squeeze_()\n",
    "                top_probs = [top_probs] if len(top_probs.size()) == 0 else top_probs\n",
    "                top_idx = [top_idx] if len(top_idx.size()) == 0 else top_idx\n",
    "                for i in range(len(top_probs)):\n",
    "                    word = top_idx[i].reshape(1, 1).to(device)\n",
    "                    new_score = c_score + top_probs[i]\n",
    "                    potential_candidates.append((torch.cat((c_sequence, word)).to(device), new_score, hidden))\n",
    "\n",
    "        candidates = sorted(potential_candidates, key= lambda x: x[1], reverse=True)[0:k] \n",
    "        potential_candidates = []\n",
    "\n",
    "    completed = completed_translations + candidates\n",
    "    completed = sorted(completed, key= lambda x: x[1], reverse=True)[0] \n",
    "    return completed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ids_to_words(ids, trg):\n",
    "    words = \"\"\n",
    "    for x in ids:\n",
    "        words += trg.vocab.itos[x.squeeze().item()] + ' '\n",
    "    return words.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chaitra said the best way to get hyperparameters for your model\n",
    "# was to take like 100, 200, 500 examples from your dataset\n",
    "# and see which hyperparameter combination overfits the best/fastest on that example. \n",
    "# And then use that as your hyperparameter combination to train the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_batch(args, encoder, decoder, encoder_optimizer, decoder_optimizer, loss_func, batch, trg, device):\n",
    "    \n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    \n",
    "    ############\n",
    "    #  encode  #\n",
    "    ############\n",
    "    \n",
    "    _, batch_size = batch.trg[0].shape\n",
    "    hidden = encoder.random_init_hidden(device, batch_size)\n",
    "    encoder_outputs, hidden = encoder(hidden, batch.src[0], batch.src[1])\n",
    "    \n",
    "    #################\n",
    "    #  beam search  #\n",
    "    #################\n",
    "    \n",
    "    max_length = 30\n",
    "    k = 2 \n",
    "    \n",
    "    translations = []\n",
    "    trg_translations = []\n",
    "    for i in range(batch_size):\n",
    "        decoder_input = torch.tensor([[src.vocab.stoi['SOS']]], device=device)\n",
    "        decoder_hidden = hidden[:, i, :].unsqueeze(1)\n",
    "        encoder_outputs_i = encoder_outputs[:, i, :].unsqueeze(1)\n",
    "\n",
    "        seq_of_ids = beam_search(decoder, decoder_input, encoder_outputs_i, decoder_hidden, max_length, k, trg)\n",
    "        translations.append(ids_to_words(seq_of_ids, trg))\n",
    "        trg_translations.append(ids_to_words(batch.trg[0][:batch.trg[1][i], i], trg))\n",
    "        \n",
    "    return translations, trg_translations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(args, encoder, decoder, encoder_optimizer, decoder_optimizer, loss_func, device, epoch_idx, \n",
    "        val_data, trg):\n",
    "    \n",
    "    # Create minibatches over validation data\n",
    "    val_iter = data.BucketIterator(\n",
    "        dataset=val_data, \n",
    "        batch_size=args.batch_size,\n",
    "        train=False,\n",
    "        shuffle=False,\n",
    "        # A key to use for sorting examples in order to batch together \n",
    "        # examples with similar lengths and minimize padding.\n",
    "        sort=True,\n",
    "        sort_key=lambda x: len(x.src),\n",
    "        repeat=False,\n",
    "        sort_within_batch=True,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    val_losses = []\n",
    "    val_bleus = []\n",
    "    val_references = []\n",
    "    \n",
    "    all_predicted = []\n",
    "    all_trg = []\n",
    "    for i, batch in enumerate(iter(val_iter)):\n",
    "        predicted_trans, trg_trans = val_batch(args, encoder, decoder, encoder_optimizer, decoder_optimizer, loss_func, batch, trg, device)\n",
    "        all_predicted += predicted_trans\n",
    "        all_trg += trg_trans\n",
    "    print(all_predicted[:10])\n",
    "    print(all_trg[:10])    \n",
    "    bleu = calculate_bleu(all_predicted, all_trg)\n",
    "    print(bleu)\n",
    "    if epoch_idx % 3 == 0:\n",
    "        with open(OUTPUT_FILE, 'a') as f:\n",
    "            f.write(str(all_predicted[:10]))\n",
    "            f.write(str(all_trg[:10]))\n",
    "            f.write(\"bleu score: {}\".format(bleu))\n",
    "            f.close()\n",
    "    return bleu\n",
    "    \n",
    "    \n",
    "#                    #\n",
    "# Batch & Dimensions #\n",
    "#                    #\n",
    "# `batch` represents a batch of examples. \n",
    "# `batch.src` consists of two tensors. \n",
    "# The first, `b.src[0]`, is the `src` examples from your batch; it's a tensor with the shape (max_seq_len, batch_size). \n",
    "# Your sequences have already been indexed and padded. \n",
    "# The second, `b.src[1]`, is the actual lengths of each sequence. It is of shape (batch_size, 1). \n",
    "\n",
    "# data.BucketIterator automatically batches sequences of similar lengths together. \n",
    "# it also automatically sorts in reverse order. \n",
    "\n",
    "# Say you have a bidirectional, 2-layer RNN encoder. A single batch has max length 19 and batch size 32. \n",
    "# The encoder_outputs will have shape: (19, 32, 512). \n",
    "# Basically, it only returns the topmost layer's hidden states at each step of the sequence. \n",
    "# And it concatenates both directional outputs (hidden states) for the topmost layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train, epoch: 0, batch number: 0, batch loss: 10.775992838541667\n",
      "train, epoch: 0, batch number: 1000, batch loss: 5.358255949733096\n",
      "train, epoch: 0, batch number: 2000, batch loss: 4.532953962873409\n",
      "epoch: 0, average loss for epoch: 5.383771311054378, size of last batch 64\n",
      "['SOS you have to be a little . EOS', \"SOS it 's going to do . EOS\", 'SOS this is the world . EOS', \"SOS there 's the world . EOS\", 'SOS this is the world . EOS', \"SOS it 's a lot . EOS\", 'SOS this is the world . EOS', 'SOS we have to be the world . EOS', \"SOS what 's you ? EOS\", \"SOS i 'm going to do . EOS\"]\n",
      "['SOS he has the most <unk> memory . EOS', 'SOS remi knows what love is . EOS', 'SOS kofi is the embodiment of possibility . EOS', 'SOS in the cold , windy night . EOS', 'SOS this is a family portrait . EOS', 'SOS it was very time-consuming . EOS', 'SOS this was the very first . EOS', 'SOS we activate communities . EOS', 'SOS guess what ? EOS', 'SOS and i was distraught . EOS']\n",
      "3.6845796719321458\n",
      "train, epoch: 1, batch number: 0, batch loss: 4.5160294596354165\n",
      "train, epoch: 1, batch number: 1000, batch loss: 4.4418733897723905\n",
      "train, epoch: 1, batch number: 2000, batch loss: 3.80115236287953\n",
      "epoch: 1, average loss for epoch: 4.188729763003378, size of last batch 64\n",
      "[\"SOS i 'm a very amazing example . EOS\", 'SOS so , let me tell you that . EOS', \"SOS it 's the robot of the universe . EOS\", \"SOS there 's a little bit of the car . EOS\", 'SOS this is the last day . EOS', \"SOS it 's a few days . EOS\", 'SOS this is the first one . EOS', 'SOS we have a lot of the food . EOS', 'SOS guess what ? EOS', \"SOS i 'm very excited . EOS\"]\n",
      "['SOS he has the most <unk> memory . EOS', 'SOS remi knows what love is . EOS', 'SOS kofi is the embodiment of possibility . EOS', 'SOS in the cold , windy night . EOS', 'SOS this is a family portrait . EOS', 'SOS it was very time-consuming . EOS', 'SOS this was the very first . EOS', 'SOS we activate communities . EOS', 'SOS guess what ? EOS', 'SOS and i was distraught . EOS']\n",
      "5.783817721503462\n",
      "train, epoch: 2, batch number: 0, batch loss: 3.788904622395833\n",
      "train, epoch: 2, batch number: 1000, batch loss: 3.912436343879745\n",
      "train, epoch: 2, batch number: 2000, batch loss: 3.3096379832119247\n",
      "epoch: 2, average loss for epoch: 3.613370633665416, size of last batch 64\n",
      "['SOS you have a wonderful theory . EOS', \"SOS what 's the reason why it is . EOS\", \"SOS it 's the robot that 's raining . EOS\", \"SOS it 's called the skin . EOS\", 'SOS this is the family . EOS', \"SOS it 's been done . EOS\", 'SOS this is the first one . EOS', 'SOS we have the tools of the community . EOS', 'SOS think about that ? EOS', 'SOS i was very lucky . EOS']\n",
      "['SOS he has the most <unk> memory . EOS', 'SOS remi knows what love is . EOS', 'SOS kofi is the embodiment of possibility . EOS', 'SOS in the cold , windy night . EOS', 'SOS this is a family portrait . EOS', 'SOS it was very time-consuming . EOS', 'SOS this was the very first . EOS', 'SOS we activate communities . EOS', 'SOS guess what ? EOS', 'SOS and i was distraught . EOS']\n",
      "7.858347193818742\n",
      "train, epoch: 3, batch number: 0, batch loss: 3.264529079861111\n",
      "train, epoch: 3, batch number: 1000, batch loss: 3.526538056976572\n",
      "train, epoch: 3, batch number: 2000, batch loss: 2.916000799614349\n",
      "epoch: 3, average loss for epoch: 3.1870903911996256, size of last batch 64\n",
      "['SOS you have a wonderful art . EOS', 'SOS the teacher is not what it is . EOS', 'SOS 7,200 is the beige . EOS', \"SOS it 's raining called the beige . EOS\", 'SOS this is the hospital . EOS', \"SOS it 's been time . EOS\", 'SOS this is the first one . EOS', \"SOS we 're focusing on the community . EOS\", 'SOS think about that ? EOS', 'SOS i was very lucky . EOS']\n",
      "['SOS he has the most <unk> memory . EOS', 'SOS remi knows what love is . EOS', 'SOS kofi is the embodiment of possibility . EOS', 'SOS in the cold , windy night . EOS', 'SOS this is a family portrait . EOS', 'SOS it was very time-consuming . EOS', 'SOS this was the very first . EOS', 'SOS we activate communities . EOS', 'SOS guess what ? EOS', 'SOS and i was distraught . EOS']\n",
      "9.004465212935516\n",
      "train, epoch: 4, batch number: 0, batch loss: 2.8397927517361112\n",
      "train, epoch: 4, batch number: 1000, batch loss: 3.2171021231835706\n",
      "train, epoch: 4, batch number: 2000, batch loss: 2.5894420298726737\n",
      "epoch: 4, average loss for epoch: 2.84369825454085, size of last batch 64\n",
      "[\"SOS he 's got a wonderful memory . EOS\", 'SOS i know what the teacher is . EOS', 'SOS solly is the beige . EOS', \"SOS it 's a flea in the air . EOS\", 'SOS this is the children in the family . EOS', \"SOS it 's a long time . EOS\", 'SOS this is the first one . EOS', 'SOS we put the tools together . EOS', 'SOS think about that ? EOS', 'SOS i was very reassured . EOS']\n",
      "['SOS he has the most <unk> memory . EOS', 'SOS remi knows what love is . EOS', 'SOS kofi is the embodiment of possibility . EOS', 'SOS in the cold , windy night . EOS', 'SOS this is a family portrait . EOS', 'SOS it was very time-consuming . EOS', 'SOS this was the very first . EOS', 'SOS we activate communities . EOS', 'SOS guess what ? EOS', 'SOS and i was distraught . EOS']\n",
      "9.863436322656737\n",
      "train, epoch: 5, batch number: 0, batch loss: 2.4870035807291666\n",
      "train, epoch: 5, batch number: 2000, batch loss: 2.3038986460118758\n",
      "epoch: 5, average loss for epoch: 2.552243566457236, size of last batch 64\n",
      "['SOS you have a perfect memory . EOS', 'SOS my parents love something . EOS', 'SOS solly is the case of nature . EOS', \"SOS it 's raining in the airport . EOS\", 'SOS this is the family of children . EOS', \"SOS it 's so long . EOS\", 'SOS this is the first one . EOS', 'SOS we put the whole community . EOS', 'SOS guess what ? EOS', 'SOS i was very reassured . EOS']\n",
      "['SOS he has the most <unk> memory . EOS', 'SOS remi knows what love is . EOS', 'SOS kofi is the embodiment of possibility . EOS', 'SOS in the cold , windy night . EOS', 'SOS this is a family portrait . EOS', 'SOS it was very time-consuming . EOS', 'SOS this was the very first . EOS', 'SOS we activate communities . EOS', 'SOS guess what ? EOS', 'SOS and i was distraught . EOS']\n",
      "10.515927102275777\n",
      "train, epoch: 6, batch number: 0, batch loss: 2.2028959147135416\n",
      "train, epoch: 6, batch number: 1000, batch loss: 2.744248359653025\n",
      "train, epoch: 6, batch number: 2000, batch loss: 2.055612651888467\n",
      "epoch: 6, average loss for epoch: 2.305146275982927, size of last batch 64\n",
      "['SOS you have a fake sense . EOS', 'SOS she loved to know what was the love of love . EOS', 'SOS solly is the beige . EOS', \"SOS it 's at the hot airport . EOS\", 'SOS this is a family of children . EOS', \"SOS it 's time time . EOS\", 'SOS this is the first one . EOS', 'SOS we put the whole network . EOS', 'SOS guess what ? EOS', 'SOS i was very reassured . EOS']\n",
      "['SOS he has the most <unk> memory . EOS', 'SOS remi knows what love is . EOS', 'SOS kofi is the embodiment of possibility . EOS', 'SOS in the cold , windy night . EOS', 'SOS this is a family portrait . EOS', 'SOS it was very time-consuming . EOS', 'SOS this was the very first . EOS', 'SOS we activate communities . EOS', 'SOS guess what ? EOS', 'SOS and i was distraught . EOS']\n",
      "11.033673303497649\n",
      "train, epoch: 7, batch number: 0, batch loss: 1.9693307834201388\n",
      "train, epoch: 7, batch number: 1000, batch loss: 2.5153226479092528\n",
      "train, epoch: 7, batch number: 2000, batch loss: 1.8198926068192949\n",
      "epoch: 7, average loss for epoch: 2.0899797784780576, size of last batch 64\n",
      "['SOS you have an emotional intelligence . EOS', 'SOS my parents love something . EOS', \"SOS whew 's values . EOS\", \"SOS it 's raining from high fire . EOS\", 'SOS these are the inuit . EOS', \"SOS it 's time time . EOS\", 'SOS this is the first one . EOS', \"SOS we 've divided the community . EOS\", 'SOS think about that . EOS', 'SOS i was very pleased . EOS']\n",
      "['SOS he has the most <unk> memory . EOS', 'SOS remi knows what love is . EOS', 'SOS kofi is the embodiment of possibility . EOS', 'SOS in the cold , windy night . EOS', 'SOS this is a family portrait . EOS', 'SOS it was very time-consuming . EOS', 'SOS this was the very first . EOS', 'SOS we activate communities . EOS', 'SOS guess what ? EOS', 'SOS and i was distraught . EOS']\n",
      "11.051540198555411\n",
      "train, epoch: 8, batch number: 0, batch loss: 1.7214885796440973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train, epoch: 8, batch number: 1000, batch loss: 2.3510034092804717\n",
      "train, epoch: 8, batch number: 2000, batch loss: 1.6176162405882712\n",
      "epoch: 8, average loss for epoch: 1.9080116925610473, size of last batch 64\n",
      "['SOS you have an emotional force . EOS', 'SOS she taught the love of something . EOS', 'SOS anna deavere : the solution is EOS', \"SOS it 's at fort accident , in a hot air . EOS\", 'SOS this is a family of children . EOS', \"SOS it 's time for time . EOS\", 'SOS this is the first one . EOS', \"SOS we 've divided the community . EOS\", 'SOS think about that . EOS', 'SOS i was very pleased . EOS']\n",
      "['SOS he has the most <unk> memory . EOS', 'SOS remi knows what love is . EOS', 'SOS kofi is the embodiment of possibility . EOS', 'SOS in the cold , windy night . EOS', 'SOS this is a family portrait . EOS', 'SOS it was very time-consuming . EOS', 'SOS this was the very first . EOS', 'SOS we activate communities . EOS', 'SOS guess what ? EOS', 'SOS and i was distraught . EOS']\n",
      "11.083072087896566\n",
      "train, epoch: 9, batch number: 0, batch loss: 1.5551380750868056\n",
      "train, epoch: 9, batch number: 1000, batch loss: 2.1904712464320135\n",
      "train, epoch: 9, batch number: 2000, batch loss: 1.4684716653403527\n",
      "epoch: 9, average loss for epoch: 1.7466025255622106, size of last batch 64\n",
      "['SOS you have a great memory . EOS', 'SOS she taught the love of what it was . EOS', \"SOS mairead is the citizen 's consciousness EOS\", \"SOS it 's at the hot airport . EOS\", 'SOS this is a family of offspring . EOS', \"SOS it 's time for time . EOS\", \"SOS here 's the first one . EOS\", \"SOS we 've divided the community . EOS\", 'SOS think about that . EOS', 'SOS i was very pleased . EOS']\n",
      "['SOS he has the most <unk> memory . EOS', 'SOS remi knows what love is . EOS', 'SOS kofi is the embodiment of possibility . EOS', 'SOS in the cold , windy night . EOS', 'SOS this is a family portrait . EOS', 'SOS it was very time-consuming . EOS', 'SOS this was the very first . EOS', 'SOS we activate communities . EOS', 'SOS guess what ? EOS', 'SOS and i was distraught . EOS']\n",
      "11.061187983237112\n",
      "train, epoch: 10, batch number: 0, batch loss: 1.394408908420139\n"
     ]
    }
   ],
   "source": [
    "src_padding_idx = src.vocab.stoi['<pad>']\n",
    "trg_padding_idx = trg.vocab.stoi['<pad>']\n",
    "EOS_IDX = trg.vocab.stoi['EOS']\n",
    "\n",
    "encoder = rnn_models.Encoder(args, src_padding_idx, len(src.vocab)).to(device)\n",
    "decoder = rnn_models.LuongAttnDecoderRNN(args, trg_padding_idx, len(trg.vocab)).to(device)\n",
    "\n",
    "# initialize weights using gaussian with 0 mean and 0.01 std, just like the paper said\n",
    "# TODO: Better initialization. Xavier?\n",
    "for net in [encoder, decoder]:\n",
    "    for name, param in net.named_parameters(): \n",
    "        #print(name, type(param), param)\n",
    "        if 'bias' in name:\n",
    "            nn.init.constant_(param, 0.0)\n",
    "        elif 'weight' in name:\n",
    "            nn.init.xavier_normal_(param)\n",
    "            \n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=args.lr)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=args.lr)\n",
    "enc_scheduler = ReduceLROnPlateau(encoder_optimizer, min_lr=1e-10,factor = 0.5,  patience=0)\n",
    "dec_scheduler = ReduceLROnPlateau(decoder_optimizer, min_lr=1e-10,factor = 0.5,  patience=0)\n",
    "\n",
    "loss_func = nn.NLLLoss()\n",
    "\n",
    "loss_history = []\n",
    "bleu_history = []\n",
    "\n",
    "for i in range(args.epochs):\n",
    "    train_loss = train(args, encoder, decoder, encoder_optimizer, \n",
    "                                     decoder_optimizer, loss_func, device, i, \n",
    "                                    train_data, val_data, trg)\n",
    "    \n",
    "    loss_history.append(train_loss)\n",
    "    bleu = val(args, encoder, decoder, encoder_optimizer, decoder_optimizer, loss_func, device, 0, val_data, trg)\n",
    "    bleu_history.append(bleu)\n",
    "    \n",
    "    torch.save(encoder.state_dict(), 'vi-en_encoder_exp_3.pth')\n",
    "    torch.save(decoder.state_dict(), 'vi-en_decoder_exp_3.pth')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "boom = [\"i am a foon\", \"boondawg in the moon.\", \"Yippe.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr\n",
    "func()\n",
    "with open('output.txt', 'a') as f:\n",
    "    f.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func():\n",
    "    for i in range(10):\n",
    "        print(i)\n",
    "        time.sleep(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
